# mlops-project


## Описание проекта

Цель данного проекта — классификация токсичных комментариев с использованием модели на основе BERT. Модель обучается предсказывать вероятность различных типов токсичности для каждого комментария. Типы токсичности включают:

- Токсичный (toxic)
- Очень токсичный (severe_toxic)
- Непристойный (obscene)
- Угроза (threat)
- Оскорбление (insult)
- Ненависть к идентичности (identity_hate)

```
.
├── config
│   └── config.yaml
├── data
│   ├── test_labels.csv.dvc
│   ├── test.csv.dvc
│   └── train.csv.dvc
├── toxic-detector
│   ├── classifiers.py
│   ├── dataset.py
│   ├── infer.py
│   └── train.py
├── docker-compose.yaml
├── Dockerfile
├── poetry.lock
├── pyproject.toml
└── README.md
```


---

## Данные

### Источники данных

Данные предоставлены в рамках соревнования на Kaggle: https://www.kaggle.com/competitions/jigsaw-toxic-comment-classification-challenge/data

## Шаги обучения

1. **Подготовка данных**:
    - Данные загружаются из CSV-файлов и токенизируются с помощью токенизатора BERT.
    - Данные разделяются на обучающую и тестовую выборки.

2. **Конфигурация модели**:
    - Конфигурация модели и гиперпараметров управляется с помощью Hydra.
    - Конфигурационные файлы находятся в корневой директории проекта (`config.yaml`).

3. **Обучение модели**:
    - Модель обучается с использованием PyTorch Lightning.
    - Процесс обучения управляется с помощью Docker Compose, что позволяет создавать изолированные и воспроизводимые среды для обучения.
    - Метрики и артефакты логируются с помощью MLflow для отслеживания экспериментов.

4. **Оценка модели**:
    - После обучения модель оценивается на тестовой выборке.
    - Результаты оценки логируются с помощью MLflow.

5. **Инференс**:
    - Для выполнения инференса используется обученная модель.
    - Результаты инференса сохраняются в CSV-файл и логируются с помощью MLflow.

